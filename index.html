<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <title>syosa: 非言語情報の抽出・可視化ツール</title>
</head>
<body>
    <h1>ツールについて</h1>
    <p>本ツール(syosa)は，人物による活動や発言が含まれる映像資料から，機械学習を用いた動画解析により登場人物の本人の表情や視線，瞬き，動作といった非言語情報の抽出を行い，音声認識による言語情報ともにタイムラインデータとして保存可能とする．</p>
<p>本ツールはWebサーバー上に実行可能な形で置くことで，Webページの形で利用可能となる．利用者がページにアクセスすると映像資料のファイルを指定することで登場人物の非言語情報の解析が行われる．読み込まれたデータはサーバーにアップロードはされず，利用者がアクセスしている計算機資源を使って処理が行われ，いかなる利用履歴やデータ収集も行われない．</p>

<h1>解析結果について</h1>
<p>非言語情報を抽出するため，映像から以下の通りの情報を取得することが可能になっている．顔の表情は登場人物の感情を反映しているため極めて重要である．首の動きや瞳の方向をトレースすることで，相手への関心の高さや心理状態などを得られる可能性がある．また手の動きや体といった身振り手振りによる情報は非言語コミュニケーションの重要な要素である．また，口の開口率については感情や声の強さなどを表しうる．年齢や性別，人物同定はコミュニケーションの理解を支援するために行っている．</p>

<ul>
    <li>身体および顔のランドマークの座標</li>

    <li>顔の姿勢</li>
    <li>顔、身体、手のジェスチャー（状態）</li>
    <li>瞳の方向</li>
    <li>口の開口率</li>
    <li>性別推定</li>
    <li>年齢推定</li>
    <li>人物同定</li>
    <li>物体（オブジェクト認識）</li>
    <li>表情</li>    
</ul>
<img src="syosa-visualization.png" alt="解析結果のビジュアライゼーション" style="width:75%;">

<p>
    また，認識した結果をタイムグラフに合わせて表示でき，必要に応じて可視化内容は変更できる．表情は，基本的な6つの感情（怒り・嫌悪・恐怖・喜び・悲しみ・驚き）の比率で表示される．横軸のタイムスケールは拡大縮小可能である．身体情報としては，頷きなどに関連する頭部の姿勢情報の可視化を行っている．ジェスチャーについても認識したものをタイムライン上に表示している．
</p>
<p>言語情報については，時間指定のテキストトラック（字幕やキャプションなど）を表示するためのウェブビデオテキストトラック形式 (WebVTT) を読み込むことで対応する．</p>
</body>
</html>
